# OYAN API Architecture

The app is powered by three APIs, each with a designated function:

---

## 1. Gemini (via Supabase Edge Function proxy)

**Endpoint:** `https://porfjjvcnixghoxnbbdt.supabase.co/functions/v1/gemini-generator`

**Role:** Content generation with prior-context awareness

**Designated functions:**
- Generate new lessons and unit content
- Create quiz questions (multiple choice, listening, match)
- Take into account prior lessons for smooth, personalized learning
- Adapt Units 2+ to Unit 1’s design format (same structure: explanation slides, examples, quiz)
- Produce content in the same JSON schema as Unit 1 (title, explanation_slides, examples, quiz)

**Usage:** Never call Gemini directly from the client. All calls go through the Edge Function.

---

## Chat Assistant (Gemini + KazLLM)

**Endpoint:** `https://porfjjvcnixghoxnbbdt.supabase.co/functions/v1/chat-assistant`

**Role:** Kazakh-only conversational tutor

**Rules (strict):**
- Responds **only in Kazakh**. Exception: brief explanations in the user's language when helping with grammar or Kazakh concepts.
- Adapts to the user's level using prior-lessons summary.
- If the user goes off topic → immediately switches back to Kazakh and steers to learning.

**Flow:** Gemini (system prompt + chat history) → KazLLM corrects Kazakh in response → return to app

**Deploy:**
```bash
supabase functions deploy chat-assistant --project-ref porfjjvcnixghoxnbbdt
```
Secrets: `GEMINI_KEY`, optional `HUGGINGFACE_ACCESS_TOKEN`, optional `HF_KAZLLM_MODEL`

---

## 2. KazLLM (via Hugging Face / Edge Function)

**Role:** Kazakh grammar correction

**Designated functions:**
- Correct the grammar of Kazakh text generated by Gemini
- Ensure explanations, examples, and quiz options are grammatically correct
- Act as a post-processing step on Gemini’s output before it is returned to the app

**Flow:** Gemini generates content → KazLLM corrects Kazakh text → content returned to app

---

## 3. Microsoft Azure (TTS)

**Endpoint:** `https://porfjjvcnixghoxnbbdt.supabase.co/functions/v1/get-kazakh-audio`

**Role:** Text-to-speech for listening questions

**Designated functions:**
- Produce audio when the user needs to hear Kazakh (e.g. listening questions)
- Used by `KazakhAudioButton` and `KazakhAudioButton.play(text:)` for syllables, words, and phrases
- Play audio in questions that require listening (listen and choose, connect by sound, etc.)

**Status:** Set `AZURE_REGION` and `AZURE_SPEECH_KEY` as Supabase secrets, then deploy:
```bash
supabase secrets set AZURE_REGION=eastus AZURE_SPEECH_KEY=your_key
supabase functions deploy get-kazakh-audio --project-ref porfjjvcnixghoxnbbdt
```
Use the region where your Azure Speech resource lives (e.g. eastus, westeurope, southeastasia). Kazakh voice kk-KZ-AigulNeural must be available in that region.

---

## Question types (same design format)

Question format stays consistent; types can vary:

| Type            | Description                                      | UI behavior                                |
|-----------------|--------------------------------------------------|--------------------------------------------|
| Multiple choice | Standard 4-option MCQ                            | Options, Check / Not sure                  |
| Listening       | Hear Kazakh, then choose                         | Play button + options (Azure TTS)          |
| Match           | Match items (e.g. syllables to soft/hard)        | Slots, draggable or tappable options       |

---

## Lesson generation flow

```
1. App requests lesson for cloud N
2. Edge Function receives: unit_summary, prior_lessons_summary, cloud_index
3. Gemini generates content (Unit 1 format, prior context)
4. KazLLM corrects Kazakh text in the output
5. Response returned to app (cached locally)
6. When a question needs audio → Azure TTS via get-kazakh-audio
```
